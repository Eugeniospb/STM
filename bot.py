"""
–§–µ–º–∏–¥–∞ v2.1 ‚Äî –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –û–û–û "–°–¢–ú"
+ –ü–∞–º—è—Ç—å 30 —Å–æ–æ–±—â–µ–Ω–∏–π
+ –†–µ–∞–∫—Ü–∏—è –Ω–∞ reply –≤ –≥—Ä—É–ø–ø–µ
"""

import os
import asyncio
import io
import re
import base64
import logging
from datetime import datetime
from pathlib import Path
from collections import defaultdict
from legal_prompts import (
    detect_legal_mode, get_system_prompt, safety_check, 
    needs_escalation, ESCALATION_WARNING, MODE_EMOJI, MODE_NAME_RU
)
from legal_prompts import (
    detect_legal_mode, get_system_prompt, safety_check, 
    needs_escalation, ESCALATION_WARNING, MODE_EMOJI, MODE_NAME_RU
)

from telegram import Update, Chat, Message
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from telegram.constants import ParseMode, ChatAction

import anthropic
# RAG –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã
import sys
sys.path.insert(0, "/opt/stm-legal-rag")
try:
    from rag_engine import get_rag
    legal_rag = get_rag()
    RAG_ENABLED = True
except Exception as e:
    legal_rag = None
    RAG_ENABLED = False
    print(f"RAG –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
from docx import Document as DocxDocument
from docx.shared import Pt, Cm, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

MODEL_CHEAP = "claude-3-haiku-20240307"
MODEL_EXPENSIVE = "claude-sonnet-4-20250514"
MAX_TOKENS_CHEAP = 2048
MAX_TOKENS_EXPENSIVE = 4096

DIRECTOR_USERNAME = "eugenio_spb"
DIRECTOR_ID = 1676748258
GROUP_ID = int(os.getenv("GROUP_ID", "-1003639268911"))
TRIGGERS = ["—Ñ–µ–º–∏–¥–∞,", "—Ñ–µ–º–∏–¥–∞ ", "—Ñ–µ–º–∏,", "—Ñ–µ–º–∏ ", "—Ñ–µ–º,", "—Ñ–µ–º "]
MEMORY_LIMIT = 30

ASSETS_DIR = Path(__file__).parent / "assets"
LOGO_PATH = ASSETS_DIR / "logo.png"

conversation_history = defaultdict(list)
# –ö–µ—à –¥–ª—è media_group (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏)
media_group_cache = {}
media_group_timers = {}
# –ö–µ—à –ø–æ—Å–ª–µ–¥–Ω–µ–π media_group –¥–ª—è reply (–ø–æ chat_id, —Ö—Ä–∞–Ω–∏–º 1 —á–∞—Å)
media_group_files_cache = {}  # {chat_id: {"files": [...], "time": datetime}}


COMPANY = {
    "full_name": "–û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´–°–¢–ú¬ª",
    "short_name": "–û–û–û ¬´–°–¢–ú¬ª",
    "inn": "7813568956", "kpp": "781401001", "ogrn": "1137847312866",
    "address": "197375, –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, —É–ª. –ú–∞—Ä—à–∞–ª–∞ –ù–æ–≤–∏–∫–æ–≤–∞ –¥.42, –õ–∏—Ç–µ—Ä –ê, –ü–æ–º–µ—â–µ–Ω–∏–µ –ü–ò–ë ‚Ññ1-–ù-113",
    "bank": "–ê–û ¬´–¢–ò–ù–¨–ö–û–§–§ –ë–ê–ù–ö¬ª", "bik": "044525974",
    "rs": "40702810810000134609", "ks": "30101810145250000974",
    "director": "–¢–∏—Ö–æ–Ω–æ–≤ –ï–≤–≥–µ–Ω–∏–π –í–∏–∫—Ç–æ—Ä–æ–≤–∏—á", "director_short": "–¢–∏—Ö–æ–Ω–æ–≤ –ï.–í.",
    "director_position": "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä",
    "phone": "+7 812 603 78 71", "email": "stm.laser@gmail.com",
}

IP_TIKHONOV = {
    "full_name": "–ò–ü –¢–∏—Ö–æ–Ω–æ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–∏–∫—Ç–æ—Ä–æ–≤–∏—á", "short_name": "–ò–ü –¢–∏—Ö–æ–Ω–æ–≤ –ê.–í.",
    "inn": "781428127765", "ogrnip": "319784700268498",
    "address": "197375, –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, —É–ª. –†–µ–ø–∏—â–µ–≤–∞ –¥.17, –∫–æ—Ä–ø.1, –∫–≤.28",
    "bank": "–ê–û ¬´–¢–ò–ù–¨–ö–û–§–§ –ë–ê–ù–ö¬ª", "bik": "044525974",
    "rs": "40802810400001208048", "ks": "30101810145250000974",
}

client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

EXPENSIVE_PATTERNS = [
    r"(—Å–æ—Å—Ç–∞–≤—å|–Ω–∞–ø–∏—à–∏|–ø–æ–¥–≥–æ—Ç–æ–≤—å|—Å–æ–∑–¥–∞–π|—Å–¥–µ–ª–∞–π).*(–¥–æ–≥–æ–≤–æ—Ä|–ø–∏—Å—å–º–æ|–ø—Ä–µ—Ç–µ–Ω–∑–∏|–ø—Ä–∏–∫–∞–∑|–∏—Å–∫|–∑–∞—è–≤–ª–µ–Ω–∏|–∞–∫—Ç)",
    r"(–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π|–ø—Ä–æ–≤–µ—Ä—å|–∏–∑—É—á–∏|–æ—Ü–µ–Ω–∏).*(–¥–æ–≥–æ–≤–æ—Ä|–¥–æ–∫—É–º–µ–Ω—Ç|–∫–æ–Ω—Ç—Ä–∞–∫—Ç)",
    r"(—Ä–∞–∑—Ä–∞–±–æ—Ç–∞–π|–ø—Ä–µ–¥–ª–æ–∂–∏).*(—Å—Ç—Ä–∞—Ç–µ–≥–∏|–ø–ª–∞–Ω|—Å—Ö–µ–º)",
]

def is_expensive_request(text: str, has_file: bool = False) -> bool:
    if has_file:
        return True
    text_lower = text.lower()
    for pattern in EXPENSIVE_PATTERNS:
        if re.search(pattern, text_lower):
            return True
    return len(text) > 500

def get_model_for_request(text: str, has_file: bool = False) -> tuple:
    if is_expensive_request(text, has_file):
        return MODEL_EXPENSIVE, MAX_TOKENS_EXPENSIVE
    return MODEL_CHEAP, MAX_TOKENS_CHEAP

def is_director(user_id: int, username: str = None) -> bool:
    return user_id == DIRECTOR_ID or (username and username.lower() == DIRECTOR_USERNAME.lower())

def has_trigger(text: str) -> tuple:
    text_lower = text.lower()
    for trigger in TRIGGERS:
        if text_lower.startswith(trigger):
            return True, text[len(trigger):].strip()
    return False, text

async def download_file(bot, file_id: str) -> bytes:
    file = await bot.get_file(file_id)
    buffer = io.BytesIO()
    await file.download_to_memory(buffer)
    buffer.seek(0)
    return buffer.read()

async def process_document(bot, document) -> tuple:
    mime_type = document.mime_type or "application/octet-stream"
    file_data = await download_file(bot, document.file_id)
    base64_data = base64.standard_b64encode(file_data).decode("utf-8")
    if mime_type == "application/pdf":
        return base64_data, "application/pdf"
    elif mime_type.startswith("image/"):
        return base64_data, mime_type
    try:
        return file_data.decode("utf-8"), "text"
    except:
        return base64_data, mime_type

async def process_photo(bot, photo) -> tuple:
    file_data = await download_file(bot, photo.file_id)
    return base64.standard_b64encode(file_data).decode("utf-8"), "image/jpeg"

def get_current_date_ru() -> str:
    months = {1:"—è–Ω–≤–∞—Ä—è",2:"—Ñ–µ–≤—Ä–∞–ª—è",3:"–º–∞—Ä—Ç–∞",4:"–∞–ø—Ä–µ–ª—è",5:"–º–∞—è",6:"–∏—é–Ω—è",7:"–∏—é–ª—è",8:"–∞–≤–≥—É—Å—Ç–∞",9:"—Å–µ–Ω—Ç—è–±—Ä—è",10:"–æ–∫—Ç—è–±—Ä—è",11:"–Ω–æ—è–±—Ä—è",12:"–¥–µ–∫–∞–±—Ä—è"}
    now = datetime.now()
    return f"{now.day} {months[now.month]} {now.year} –≥."

def build_system_prompt(query: str = None) -> str:
    base = f"""–¢—ã ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç "–§–µ–º–∏–¥–∞" –∫–æ–º–ø–∞–Ω–∏–∏ {COMPANY['short_name']}.

–ó–ê–î–ê–ß–ò: –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑ –¥–æ–≥–æ–≤–æ—Ä–æ–≤, –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ –ì–ö/–¢–ö/–ù–ö –†–§.

–†–ï–ö–í–ò–ó–ò–¢–´ –û–û–û ¬´–°–¢–ú¬ª: –ò–ù–ù {COMPANY['inn']}, –ö–ü–ü {COMPANY['kpp']}, –û–ì–†–ù {COMPANY['ogrn']}
–ê–¥—Ä–µ—Å: {COMPANY['address']}
–†/—Å: {COMPANY['rs']}, –ë–∞–Ω–∫: {COMPANY['bank']}, –ë–ò–ö: {COMPANY['bik']}
–î–∏—Ä–µ–∫—Ç–æ—Ä: {COMPANY['director']}

–†–ï–ö–í–ò–ó–ò–¢–´ –ò–ü –¢–∏—Ö–æ–Ω–æ–≤ –ê.–í.: –ò–ù–ù {IP_TIKHONOV['inn']}, –û–ì–†–ù–ò–ü {IP_TIKHONOV['ogrnip']}, –†/—Å: {IP_TIKHONOV['rs']}

–°–ï–ì–û–î–ù–Ø: {get_current_date_ru()}

–û–±—Ä–∞—â–∞–π—Å—è –Ω–∞ "–≤—ã" –∏–ª–∏ "–ï–≤–≥–µ–Ω–∏–π". –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç –û–û–û –°–¢–ú."""

    if RAG_ENABLED and legal_rag and query:
        try:
            legal_context = legal_rag.get_context_for_query(query, max_chars=2500)
            if legal_context:
                base += "\n\nüìö –†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –°–¢–ê–¢–¨–ò –ó–ê–ö–û–ù–û–î–ê–¢–ï–õ–¨–°–¢–í–ê:\n" + legal_context
        except:
            pass
    return base

def add_to_memory(chat_id: int, role: str, content: str):
    conversation_history[chat_id].append({"role": role, "content": content})
    if len(conversation_history[chat_id]) > MEMORY_LIMIT:
        conversation_history[chat_id] = conversation_history[chat_id][-MEMORY_LIMIT:]

def get_memory(chat_id: int) -> list:
    return conversation_history[chat_id].copy()

def clear_memory(chat_id: int):
    conversation_history[chat_id] = []

async def generate_response(chat_id: int, text: str, file_data: tuple = None) -> tuple:
    has_file = file_data is not None
    model, max_tokens = get_model_for_request(text, has_file)
    logger.info(f"–ó–∞–ø—Ä–æ—Å ‚Üí –º–æ–¥–µ–ª—å: {model}, —Ñ–∞–π–ª: {has_file}, —Ä–µ–∂–∏–º: {legal_mode}")
    
    try:
        if file_data and file_data[0]:
            base64_data, media_type = file_data
            if media_type == "text":
                current_content = [{"type": "text", "text": f"–§–∞–π–ª:\n{base64_data}\n\n–ó–∞–ø—Ä–æ—Å: {text}"}]
            elif media_type == "application/pdf":
                current_content = [
                    {"type": "document", "source": {"type": "base64", "media_type": "application/pdf", "data": base64_data}},
                    {"type": "text", "text": text or "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç."}
                ]
            else:
                current_content = [
                    {"type": "image", "source": {"type": "base64", "media_type": media_type, "data": base64_data}},
                    {"type": "text", "text": text or "–ß—Ç–æ –Ω–∞ —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ?"}
                ]
        else:
            current_content = text
        
        messages = get_memory(chat_id)
        messages.append({"role": "user", "content": current_content})
        
        message = client.messages.create(model=model, max_tokens=max_tokens, system=build_system_prompt(text), messages=messages)
        response_text = message.content[0].text
        
        add_to_memory(chat_id, "user", text)
        add_to_memory(chat_id, "assistant", response_text)
        
        logger.info(f"–¢–æ–∫–µ–Ω—ã: in={message.usage.input_tokens}, out={message.usage.output_tokens}, –ø–∞–º—è—Ç—å: {len(get_memory(chat_id))}")
        return response_text, model
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Claude: {e}")
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}", model

def create_docx_on_letterhead(content: str) -> io.BytesIO:
    doc = DocxDocument()
    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.font.size = Pt(12)
    
    for section in doc.sections:
        section.top_margin = Cm(2)
        section.bottom_margin = Cm(2)
        section.left_margin = Cm(3)
        section.right_margin = Cm(1.5)
    
    header = doc.sections[0].header
    header_table = header.add_table(rows=1, cols=2, width=Inches(6.5))
    header_table.columns[0].width = Inches(1.2)
    header_table.columns[1].width = Inches(5.3)
    
    logo_cell = header_table.cell(0, 0)
    if LOGO_PATH.exists():
        logo_para = logo_cell.paragraphs[0]
        logo_run = logo_para.add_run()
        logo_run.add_picture(str(LOGO_PATH), width=Inches(1))
    
    text_cell = header_table.cell(0, 1)
    name_para = text_cell.paragraphs[0]
    name_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run1 = name_para.add_run("–û–ë–©–ï–°–¢–í–û –° –û–ì–†–ê–ù–ò–ß–ï–ù–ù–û–ô –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨–Æ")
    run1.font.bold = True
    run1.font.size = Pt(11)
    
    p2 = text_cell.add_paragraph()
    p2.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run2 = p2.add_run("¬´–°–¢–ú¬ª")
    run2.font.bold = True
    run2.font.size = Pt(14)
    run2.font.color.rgb = RGBColor(0, 112, 192)
    
    p3 = text_cell.add_paragraph()
    p3.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run3 = p3.add_run(f"{COMPANY['address']}\n–ò–ù–ù {COMPANY['inn']} ¬∑ –ö–ü–ü {COMPANY['kpp']} ¬∑ –û–ì–†–ù {COMPANY['ogrn']}")
    run3.font.size = Pt(8)
    
    line = header.add_paragraph()
    line.alignment = WD_ALIGN_PARAGRAPH.CENTER
    lr = line.add_run("‚îÄ" * 85)
    lr.font.size = Pt(8)
    lr.font.color.rgb = RGBColor(0, 112, 192)
    
    doc.add_paragraph()
    for para_text in content.split('\n'):
        if para_text.strip():
            p = doc.add_paragraph()
            stripped = para_text.strip()
            if stripped.isupper() or any(stripped.startswith(x) for x in ['–î–û–ì–û–í–û–†','–ü–†–ò–ö–ê–ó','–ü–†–ï–¢–ï–ù–ó–ò–Ø','–ê–ö–¢','–ü–ò–°–¨–ú–û']):
                p.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = p.add_run(stripped)
                run.bold = True
            else:
                p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                p.paragraph_format.first_line_indent = Cm(1.25)
                run = p.add_run(stripped)
            run.font.name = 'Times New Roman'
            run.font.size = Pt(12)
    
    doc.add_paragraph()
    doc.add_paragraph()
    sig = doc.add_paragraph()
    sig.add_run(f"{COMPANY['director_position']}                    _____________    {COMPANY['director_short']}")
    
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    if not is_director(user.id, user.username):
        await update.message.reply_text("‚öñÔ∏è –§–µ–º–∏–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É –û–û–û ¬´–°–¢–ú¬ª.")
        return
    await update.message.reply_text(
        "‚öñÔ∏è *–§–µ–º–∏–¥–∞ v2.1* ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –û–û–û ¬´–°–¢–ú¬ª\n\n"
        "‚Ä¢ –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–æ–≤, –ø–∏—Å–µ–º, –ø—Ä–µ—Ç–µ–Ω–∑–∏–π\n"
        "‚Ä¢ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (PDF, —Ñ–æ—Ç–æ)\n"
        "‚Ä¢ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏\n\n"
        f"_–ü–∞–º—è—Ç—å: {MEMORY_LIMIT} —Å–æ–æ–±—â–µ–Ω–∏–π_\n"
        "_–í –≥—Ä—É–ø–ø–µ: –§–µ–º–∏–¥–∞, ... –∏–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –º–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ_\n\n"
        "/clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å",
        parse_mode=ParseMode.MARKDOWN
    )

async def cmd_clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    clear_memory(chat_id)
    await update.message.reply_text("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")

async def cmd_requisites(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        f"üìã *–†–µ–∫–≤–∏–∑–∏—Ç—ã –û–û–û ¬´–°–¢–ú¬ª*\n\n"
        f"–ò–ù–ù: `{COMPANY['inn']}`\n–ö–ü–ü: `{COMPANY['kpp']}`\n–û–ì–†–ù: `{COMPANY['ogrn']}`\n"
        f"–ê–¥—Ä–µ—Å: {COMPANY['address']}\n\n"
        f"–ë–∞–Ω–∫: {COMPANY['bank']}\n–†/—Å: `{COMPANY['rs']}`\n–ë–ò–ö: `{COMPANY['bik']}`\n\n"
        f"–î–∏—Ä–µ–∫—Ç–æ—Ä: {COMPANY['director']}",
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    if not message:
        return
    
    user = update.effective_user
    chat = update.effective_chat
    bot_id = context.bot.id
    
    # === –û–ë–†–ê–ë–û–¢–ö–ê MEDIA_GROUP (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤) ===
    if message.media_group_id:
        mg_id = message.media_group_id
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–µ—à
        if mg_id not in media_group_cache:
            media_group_cache[mg_id] = {"files": [], "text": "", "message": message, "user": user, "chat": chat}
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª
        if message.document:
            fd = await process_document(context.bot, message.document)
            if fd:
                media_group_cache[mg_id]["files"].append(fd)
        elif message.photo:
            fd = await process_photo(context.bot, message.photo[-1])
            if fd:
                media_group_cache[mg_id]["files"].append(fd)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º caption
        if message.caption:
            media_group_cache[mg_id]["text"] = message.caption.strip()
        
        # –û—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–∞–π–º–µ—Ä
        if mg_id in media_group_timers:
            media_group_timers[mg_id].cancel()
        
        # –¢–∞–π–º–µ—Ä –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
        async def process_mg():
            await asyncio.sleep(1.5)
            if mg_id in media_group_cache:
                data = media_group_cache.pop(mg_id)
                media_group_timers.pop(mg_id, None)
                files_list = data["files"]
                txt = data["text"] or f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ {len(files_list)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                msg = data["message"]
                usr = data["user"]
                cht = data["chat"]
                
                if cht.type in [Chat.GROUP, Chat.SUPERGROUP]:
                    if not is_director(usr.id, usr.username):
                        return
                    has_trig, clean_txt = has_trigger(txt)
                    if has_trig:
                        await process_request_multi(msg, clean_txt, files_list, context)
                elif cht.type == Chat.PRIVATE:
                    if is_director(usr.id, usr.username):
                        await process_request_multi(msg, txt, files_list, context)
        
        task = asyncio.create_task(process_mg())
        media_group_timers[mg_id] = task
        return
    
    # === –û–ë–´–ß–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (–æ–¥–∏–Ω —Ñ–∞–π–ª) ===
    text = message.text or message.caption or ""
    text = text.strip()
    
    file_data = None
    if message.document:
        file_data = await process_document(context.bot, message.document)
    elif message.photo:
        file_data = await process_photo(context.bot, message.photo[-1])
    
    if file_data and not text:
        text = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç."
    
    if not text and not file_data:
        return
    
    if chat.type == Chat.PRIVATE:
        if not is_director(user.id, user.username):
            await message.reply_text("‚öñÔ∏è –§–µ–º–∏–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É –û–û–û ¬´–°–¢–ú¬ª.")
            return
        await process_request(message, text, file_data, context)
        return
    
    if chat.type in [Chat.GROUP, Chat.SUPERGROUP]:
        if not is_director(user.id, user.username):
            return
        
        has_trig, clean_text = has_trigger(text)
        is_reply_to_bot = message.reply_to_message and message.reply_to_message.from_user and message.reply_to_message.from_user.id == bot_id
        

        # –ë–µ—Ä—ë–º —Ñ–∞–π–ª—ã –∏–∑ reply –µ—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–µ—Ç
        if not file_data and message.reply_to_message:
            reply_msg = message.reply_to_message
            reply_id = reply_msg.message_id
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à media_group (–ø–æ chat_id)
            if chat.id in media_group_files_cache:
                cached = media_group_files_cache[chat.id]
                if (datetime.now() - cached["time"]).seconds < 3600:
                    files_list = cached["files"]
                    has_trig, clean_text = has_trigger(text)
                    if has_trig:
                        await process_request_multi(message, clean_text, files_list, context)
                        return
            
            # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–∑ reply
            if reply_msg.document:
                file_data = await process_document(context.bot, reply_msg.document)
            elif reply_msg.photo:
                file_data = await process_photo(context.bot, reply_msg.photo[-1])
        if has_trig:
            await process_request(message, clean_text, file_data, context)
        elif is_reply_to_bot:
            await process_request(message, text, file_data, context)


async def process_request_multi(message: Message, text: str, files_list: list, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏"""
    chat_id = message.chat_id
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à –¥–ª—è –±—É–¥—É—â–∏—Ö reply (–ø–æ chat_id)
    media_group_files_cache[chat_id] = {
        "files": files_list,
        "time": datetime.now()
    }
    # –ß–∏—Å—Ç–∏–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ (>1 —á–∞—Å–∞)
    old_ids = [k for k, v in media_group_files_cache.items() 
               if (datetime.now() - v["time"]).seconds > 3600]
    for k in old_ids:
        media_group_files_cache.pop(k, None)
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
    combined_content = []
    for i, file_data in enumerate(files_list, 1):
        base64_data, media_type = file_data
        combined_content.append({
            "type": "document" if media_type == "application/pdf" else "image",
            "source": {"type": "base64", "media_type": media_type, "data": base64_data}
        })
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Claude
    messages_content = combined_content + [{"type": "text", "text": text}]
    
    model = MODEL_EXPENSIVE  # –í—Å–µ–≥–¥–∞ Sonnet –¥–ª—è –º—É–ª—å—Ç–∏—Ñ–∞–π–ª–æ–≤
    
    # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
    legal_context = ""
    if RAG_ENABLED and legal_rag:
        legal_context = legal_rag.get_context_for_query(text)
    
    system, legal_mode, escalation_flag = build_system_prompt(text, has_file)
    if legal_context:
        system += f"\n\n–ü–†–ê–í–û–í–ê–Ø –ë–ê–ó–ê:\n{legal_context}"
    
    try:
        response = client.messages.create(
            model=model,
            max_tokens=MAX_TOKENS_EXPENSIVE,
            system=system,
            messages=[{"role": "user", "content": messages_content}]
        )
        result = response.content[0].text
        logger.info(f"–ú—É–ª—å—Ç–∏—Ñ–∞–π–ª: {len(files_list)} —Ñ–∞–π–ª–æ–≤, —Ç–æ–∫–µ–Ω—ã: in={response.usage.input_tokens}, out={response.usage.output_tokens}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Claude: {e}")
        result = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}"
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
    text_lower = text.lower()
    need_docx = any(phrase in text_lower for phrase in ["–Ω–∞ –±–ª–∞–Ω–∫–µ", "—Å–æ–∑–¥–∞–π –æ—Ç–≤–µ—Ç", "—Å–æ–∑–¥–∞–π –ø–∏—Å—å–º–æ", "–ø–æ–¥–≥–æ—Ç–æ–≤—å –æ—Ç–≤–µ—Ç"])
    
    if len(result) > 4000:
        for i in range(0, len(result), 4000):
            await message.reply_text(result[i:i+4000])
    else:
        try:
            await message.reply_text(result, parse_mode=ParseMode.MARKDOWN)
        except:
            await message.reply_text(result)
    
    if need_docx:
        from companies import find_company
        company_key, company_data = find_company(text_lower)
        if company_key:
            docx_buffer = create_docx_on_letterhead(result)
            await message.reply_document(
                document=docx_buffer,
                filename=f"STM_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
                caption=f"üìÑ –ù–∞ –±–ª–∞–Ω–∫–µ {company_data['short_name']}"
            )

async def process_request(message: Message, text: str, file_data: tuple, context: ContextTypes.DEFAULT_TYPE):
    chat_id = message.chat_id
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    text_lower = text.lower()
    if "—Ä–µ–∫–≤–∏–∑–∏—Ç—ã" in text_lower and not file_data:
        if "–∏–ø" in text_lower:
            await message.reply_text(
                f"üìã *–†–µ–∫–≤–∏–∑–∏—Ç—ã –ò–ü –¢–∏—Ö–æ–Ω–æ–≤ –ê.–í.*\n\n–ò–ù–ù: `{IP_TIKHONOV['inn']}`\n–û–ì–†–ù–ò–ü: `{IP_TIKHONOV['ogrnip']}`\n"
                f"–ê–¥—Ä–µ—Å: {IP_TIKHONOV['address']}\n\n–ë–∞–Ω–∫: {IP_TIKHONOV['bank']}\n–†/—Å: `{IP_TIKHONOV['rs']}`\n–ë–ò–ö: `{IP_TIKHONOV['bik']}`",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        elif "—Å—Ç–º" in text_lower or "–æ–æ–æ" in text_lower or text_lower.strip() == "—Ä–µ–∫–≤–∏–∑–∏—Ç—ã":
            await cmd_requisites(Update(0, message=message), context)
            return
    
    response, model_used = await generate_response(chat_id, text, file_data)
    

    # DOCX —Ç–æ–ª—å–∫–æ –ø–æ —è–≤–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É: "—Å–æ–∑–¥–∞–π –Ω–∞ –±–ª–∞–Ω–∫–µ –ò–ü/–û–û–û/–¢—Ä–∏—Ñ–æ–Ω–æ–≤–∞"
    need_docx = False
    company_key = None
    if any(phrase in text_lower for phrase in ["–Ω–∞ –±–ª–∞–Ω–∫–µ", "–Ω–∞ –±–ª–∞–Ω–∫ ", "—Å–æ–∑–¥–∞–π –æ—Ç–≤–µ—Ç", "—Å–æ–∑–¥–∞–π –ø–∏—Å—å–º–æ", "—Å–æ–∑–¥–∞–π –ø—Ä–µ—Ç–µ–Ω–∑–∏—é", "–ø–æ–¥–≥–æ—Ç–æ–≤—å –æ—Ç–≤–µ—Ç", "–ø–æ–¥–≥–æ—Ç–æ–≤—å –ø–∏—Å—å–º–æ"]):
        from companies import find_company
        company_key, company_data = find_company(text_lower)
        if company_key:
            need_docx = True
    
    if len(response) > 4000:
        if need_docx:
            docx_buffer = create_docx_on_letterhead(response)
            await message.reply_document(document=docx_buffer, filename=f"STM_{datetime.now().strftime('%Y%m%d_%H%M')}.docx", caption="üìÑ –î–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –±–ª–∞–Ω–∫–µ –°–¢–ú")
        else:
            for i in range(0, len(response), 4000):
                await message.reply_text(response[i:i+4000])
    else:
        try:
            await message.reply_text(response, parse_mode=ParseMode.MARKDOWN)
        except:
            await message.reply_text(response)
        if need_docx and len(response) > 200:
            docx_buffer = create_docx_on_letterhead(response)
            await message.reply_document(document=docx_buffer, filename=f"STM_{datetime.now().strftime('%Y%m%d_%H%M')}.docx", caption="üìÑ –ù–∞ –±–ª–∞–Ω–∫–µ")
    
    logger.info(f"{'üí∞ Sonnet' if model_used == MODEL_EXPENSIVE else 'üíö Haiku'}, {len(response)} —Å–∏–º–≤.")

def main():
    if not TELEGRAM_TOKEN or not ANTHROPIC_API_KEY:
        raise ValueError("–¢–æ–∫–µ–Ω—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")
    ASSETS_DIR.mkdir(exist_ok=True)
    app = Application.builder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("help", cmd_start))
    app.add_handler(CommandHandler("clear", cmd_clear))
    app.add_handler(CommandHandler("requisites", cmd_requisites))
    app.add_handler(MessageHandler(filters.TEXT | filters.PHOTO | filters.Document.ALL, handle_message))
    logger.info(f"üöÄ –§–µ–º–∏–¥–∞ v2.1 | –ü–∞–º—è—Ç—å: {MEMORY_LIMIT} | –õ–æ–≥–æ—Ç–∏–ø: {'‚úì' if LOGO_PATH.exists() else '‚úó'}")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
